{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/siyuanzhou/Nutstore Files/developer/2017intercultural/sub-project/14.0NLP/code/'\n",
    "save_dir = '/Users/siyuanzhou/Nutstore Files/developer/2017intercultural/sub-project/14.0NLP/output/resultsflow6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nbformat\n",
    "import graphviz\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/siyuanzhou/Nutstore Files/developer/2017intercultural/sub-project/14.0NLP/output/resultsflow6.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_variable_assignments(code):\n",
    "    \"\"\" Parse Python code to find all variable assignments. \"\"\"\n",
    "    tree = ast.parse(code)\n",
    "    assignments = {}\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and len(node.targets) == 1 and isinstance(node.targets[0], ast.Name):\n",
    "            var_name = node.targets[0].id\n",
    "            try:\n",
    "                if isinstance(node.value, ast.Str):\n",
    "                    assignments[var_name] = node.value.s\n",
    "                elif isinstance(node.value, ast.BinOp) and isinstance(node.value.op, (ast.Add, ast.Mod)):\n",
    "                    values = [node.value.left, node.value.right]\n",
    "                    resolved_values = []\n",
    "                    for v in values:\n",
    "                        if isinstance(v, ast.Str):\n",
    "                            resolved_values.append(v.s)\n",
    "                        elif isinstance(v, ast.Name) and v.id in assignments:\n",
    "                            resolved_values.append(assignments[v.id])\n",
    "                    if len(resolved_values) == len(values):\n",
    "                        assignments[var_name] = ''.join(resolved_values)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return assignments\n",
    "\n",
    "def clean_code(code):\n",
    "    \"\"\" Remove lines that start with '%' or '!', common in Jupyter notebooks as magic commands and shell commands. \"\"\"\n",
    "    cleaned_lines = []\n",
    "    for line in code.splitlines():\n",
    "        if not line.strip().startswith(('%', '!')):\n",
    "            cleaned_lines.append(line)\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def replace_variables_in_path_and_trim(path, variables):\n",
    "    \"\"\" Replace variables in the file path and only return the base filename. \"\"\"\n",
    "    original_path = path\n",
    "    for var, value in variables.items():\n",
    "        path = path.replace(var, value)\n",
    "    if path == original_path and '+' in path:\n",
    "        path = re.sub(r\"[\\w\\s]*\\+\\s*['\\\"]\", \"\", path)\n",
    "    path = re.sub(r\"[\\'+\\s]+\", \"\", path)\n",
    "    return os.path.basename(path)\n",
    "\n",
    "def extract_operations_from_code(code, file_operations):\n",
    "    \"\"\" Extract file operations from code and replace variables in paths. \"\"\"\n",
    "    variables = parse_variable_assignments(code)\n",
    "    patterns = {\n",
    "        \"read_csv\": r\"read_csv\\((.*?)\\)\",\n",
    "        \"read_json\": r\"read_json\\((.*?)\\)\",\n",
    "        \"to_csv\": r\"to_csv\\((.*?)\\)\",\n",
    "        \"to_json\": r\"to_json\\((.*?)\\)\"\n",
    "    }\n",
    "    for operation, pattern in patterns.items():\n",
    "        matches = re.findall(pattern, code, re.DOTALL)\n",
    "        for match in matches:\n",
    "            file_name = match.split(',')[0].strip().strip('\"').strip(\"'\")\n",
    "            file_name = replace_variables_in_path_and_trim(file_name, variables)\n",
    "            if 'read_' in operation:\n",
    "                file_operations['inputs'].add(file_name)\n",
    "            elif 'to_' in operation:\n",
    "                file_operations['outputs'].add(file_name)\n",
    "    return file_operations\n",
    "\n",
    "def extract_file_operations_from_ipynb(nb_path):\n",
    "    \"\"\" Extract file operations from a Jupyter notebook after cleaning the code. \"\"\"\n",
    "    with open(nb_path, 'r', encoding='utf-8') as nb_file:\n",
    "        nb = nbformat.read(nb_file, as_version=4)\n",
    "    file_operations = {'inputs': set(), 'outputs': set()}\n",
    "    for cell in nb['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            cleaned_code = clean_code(cell['source'])\n",
    "            try:\n",
    "                file_operations = extract_operations_from_code(cleaned_code, file_operations)\n",
    "            except SyntaxError:\n",
    "                # Handle potential syntax errors from remaining non-standard code\n",
    "                continue\n",
    "    return file_operations\n",
    "\n",
    "def extract_file_operations_from_py(py_path):\n",
    "    \"\"\" Extract file operations from a Python script. \"\"\"\n",
    "    with open(py_path, 'r', encoding='utf-8') as py_file:\n",
    "        code = py_file.read()\n",
    "    file_operations = {'inputs': set(), 'outputs': set()}\n",
    "    file_operations = extract_operations_from_code(code, file_operations)\n",
    "    return file_operations\n",
    "\n",
    "def create_flowchart(file_ops):\n",
    "    \"\"\" Create a flowchart of file operations using Graphviz. \"\"\"\n",
    "    dot = graphviz.Digraph(comment='Data Analysis Workflow', graph_attr={'rankdir': 'LR'})\n",
    "    for nb_name, ops in file_ops.items():\n",
    "        dot.node(nb_name, nb_name.split('.')[0], shape='box')\n",
    "        for input_file in ops['inputs']:\n",
    "            dot.node(input_file, input_file, shape='cylinder')\n",
    "            dot.edge(input_file, nb_name, label='input')\n",
    "        for output_file in ops['outputs']:\n",
    "            dot.node(output_file, output_file, shape='cylinder')\n",
    "            dot.edge(nb_name, output_file, label='output')\n",
    "    return dot\n",
    "\n",
    "def process_files_recursively(folder_path):\n",
    "    \"\"\" Recursively process .ipynb and .py files in directories and subdirectories. \"\"\"\n",
    "    file_ops_dict = {}\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file.endswith('.ipynb'):\n",
    "                try:\n",
    "                    file_ops_dict[file] = extract_file_operations_from_ipynb(file_path)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON for file: {file_path}\")\n",
    "            elif file.endswith('.py'):\n",
    "                file_ops_dict[file] = extract_file_operations_from_py(file_path)\n",
    "    return file_ops_dict\n",
    "\n",
    "# Main execution logic: apply the functions to files in a specified directory\n",
    "file_ops_dict = process_files_recursively(folder_path)\n",
    "\n",
    "flowchart = create_flowchart(file_ops_dict)\n",
    "flowchart.render(save_dir, format='pdf', cleanup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
